{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLbJZi_ZtKqG",
        "outputId": "776f39e6-1622-4bc5-c8f8-2566fc5c297e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxzNxWyKtOAE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a58bfbfd-f452-4f0f-c526-a949b2418169"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wordninja\n",
            "  Downloading wordninja-2.0.0.tar.gz (541 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m541.6/541.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wordninja\n",
            "  Building wheel for wordninja (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wordninja: filename=wordninja-2.0.0-py3-none-any.whl size=541530 sha256=b5c89844a55bcf1bf6688c47a4971775f060da56354aa837b4e66846b697fbf9\n",
            "  Stored in directory: /root/.cache/pip/wheels/e6/66/9c/712044a983337f5d44f90abcd244bd4b8ad28ee64750404b50\n",
            "Successfully built wordninja\n",
            "Installing collected packages: wordninja\n",
            "Successfully installed wordninja-2.0.0\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "%%capture\n",
        "zip_path = '/content/drive/MyDrive/GenClass/temp/modelset.zip'\n",
        "extract_folder = '/content/drive/MyDrive/GenClass/temp/'\n",
        "\n",
        "!unzip -o \"{zip_path}\" -d \"{extract_folder}\"\n",
        "\"\"\"\n",
        "!pip install wordninja"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7G21i93pEi0"
      },
      "outputs": [],
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import json\n",
        "import re\n",
        "import urllib.parse\n",
        "import unicodedata\n",
        "import wordninja\n",
        "class XMI2AST:\n",
        "    primitive_types = {\"string\", \"boolean\", \"int\", \"float\", \"double\", \"long\", \"short\", \"byte\", \"char\"}\n",
        "\n",
        "    @staticmethod\n",
        "    def normalize_type(raw_type: str) -> str:\n",
        "        if not raw_type:\n",
        "            return \"\"\n",
        "\n",
        "        # Decode URL-encoded characters\n",
        "        raw_type = urllib.parse.unquote(raw_type)\n",
        "\n",
        "        # Remove leading/trailing whitespace\n",
        "        raw_type = raw_type.strip()\n",
        "\n",
        "        # Ignore internal reference types that start with \"_\"\n",
        "        if raw_type.startswith(\"_\"):\n",
        "            return \"\"\n",
        "\n",
        "        # Remove XMI href parts (e.g., path#//Type)\n",
        "        if '//' in raw_type:\n",
        "            raw_type = raw_type.split('//')[-1]\n",
        "\n",
        "        # Normalize known variations\n",
        "        normalization_map = {\n",
        "            \"integer\": \"int\",\n",
        "            \"bool\": \"boolean\",\n",
        "            \"boolean\": \"boolean\",\n",
        "            \"string\": \"string\",\n",
        "            \"float\": \"float\",\n",
        "            \"double\": \"double\",\n",
        "            \"long\": \"long\",\n",
        "            \"short\": \"short\",\n",
        "            \"byte\": \"byte\",\n",
        "            \"char\": \"char\"\n",
        "        }\n",
        "\n",
        "        lower_type = raw_type.lower()\n",
        "        if lower_type in normalization_map:\n",
        "            return normalization_map[lower_type]\n",
        "\n",
        "        return raw_type[0].upper() + raw_type[1:]\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def to_pascal_case(name: str) -> str:\n",
        "        if not name:\n",
        "            return \"\"\n",
        "\n",
        "        # First split on delimiters like space, underscore, dash\n",
        "        parts = re.split(r'[\\s_-]+', name.strip())\n",
        "\n",
        "        # If splitting didn't produce multiple parts, use wordninja\n",
        "        if len(parts) == 1:\n",
        "            parts = wordninja.split(name)\n",
        "\n",
        "        return ''.join(word.capitalize() for word in parts if word)\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def to_camel_case(name: str) -> str:\n",
        "        if not name:\n",
        "            return \"\"\n",
        "\n",
        "        # First try splitting by delimiters (_ - space)\n",
        "        parts = re.split(r'[\\s_-]+', name.strip())\n",
        "\n",
        "        # If splitting fails (i.e., only one part and all lowercase), use wordninja\n",
        "        if len(parts) == 1 and parts[0].islower():\n",
        "            parts = wordninja.split(name.strip())\n",
        "\n",
        "        if not parts:\n",
        "            return \"\"\n",
        "\n",
        "        return parts[0].lower() + ''.join(word.capitalize() for word in parts[1:])\n",
        "\n",
        "    @staticmethod\n",
        "    def lower_first_letter(s: str) -> str:\n",
        "        if not s:\n",
        "            return s\n",
        "        return s[0].lower() + s[1:]\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_visibility(visibility):\n",
        "        mapping = {\n",
        "            \"public\": \"+\",\n",
        "            \"private\": \"-\",\n",
        "            \"protected\": \"#\",\n",
        "            \"package\": \"~\"\n",
        "        }\n",
        "        return mapping.get(visibility, \"+\")\n",
        "\n",
        "    def is_pascal_case(s: str) -> bool:\n",
        "        \"\"\"\n",
        "        Returns True if the input string follows PascalCase naming.\n",
        "        \"\"\"\n",
        "        pattern = r'^[A-Z][a-z0-9]*(?:[A-Z][a-z0-9]*)*$'\n",
        "        return bool(re.match(pattern, s))\n",
        "\n",
        "    @staticmethod\n",
        "    def replace_and_or(s: str) -> str:\n",
        "        # Step 1: Strip / or & at the start or end\n",
        "        s = s.strip('/&,')\n",
        "\n",
        "        # Step 2: Split by / or & inside the string\n",
        "        parts = re.split(r'([/&,])', s)\n",
        "\n",
        "        # Step 3: Rebuild with replacements\n",
        "        result_parts = []\n",
        "        i = 0\n",
        "        while i < len(parts):\n",
        "            part = parts[i]\n",
        "            if part == '/':\n",
        "                result_parts.append(\"Or\")\n",
        "                i += 1\n",
        "            elif part == '&' or part == ',':\n",
        "                result_parts.append(\"And\")\n",
        "                i += 1\n",
        "            else:\n",
        "                # Normal string part — capitalize first letter, keep rest as is\n",
        "                cleaned = part.strip()\n",
        "                if cleaned:\n",
        "                    result_parts.append(cleaned[0] + cleaned[1:])\n",
        "                i += 1\n",
        "\n",
        "        # Join all parts\n",
        "        return ''.join(result_parts)\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def is_camel_case(s: str) -> bool:\n",
        "        \"\"\"\n",
        "        Returns True if the input string follows camelCase naming.\n",
        "        \"\"\"\n",
        "        pattern = r'^[a-z0-9]+(?:[A-Z][a-z0-9]*)*$'\n",
        "        return bool(re.match(pattern, s))\n",
        "\n",
        "    @staticmethod\n",
        "    def remove_after_char(s: str, specific_char) -> str:\n",
        "        return s.split(specific_char, 1)[0]\n",
        "\n",
        "    @staticmethod\n",
        "    def remove_accents(text: str) -> str:\n",
        "        # Normalize string to decomposed form (NFKD)\n",
        "        nfkd_form = unicodedata.normalize('NFKD', text)\n",
        "        # Filter out combining characters (accents)\n",
        "        return ''.join(c for c in nfkd_form if not unicodedata.combining(c))\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_after_last_dot_if_java(s: str) -> str:\n",
        "        if s.startswith(\"Java\"):\n",
        "            return s.split(\".\")[-1]\n",
        "        return s\n",
        "\n",
        "    @staticmethod\n",
        "    def remove_after_brackets_and_parentheses(s: str) -> str:\n",
        "        # Step 1: Remove everything after and including the first '['\n",
        "        if '[' in s:\n",
        "            s = s.split('[')[0]\n",
        "\n",
        "        # Step 2: Remove everything after and including the first '('\n",
        "        if '(' in s:\n",
        "            s = s.split('(')[0]\n",
        "\n",
        "        return s\n",
        "\n",
        "    @staticmethod\n",
        "    def replace_part(s: str, replaced: str, replacement: str = \"\") -> str:\n",
        "        return s.replace(replaced, replacement)\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_generic_type(s: str) -> str:\n",
        "        match = re.search(r'<\\s*([a-zA-Z0-9_]+)\\s*>', s)\n",
        "        if match:\n",
        "            return match.group(1)\n",
        "        return s  # return original if no angle brackets found\n",
        "\n",
        "    def extract_inner_generic(s: str) -> str:\n",
        "        match = re.search(r'<\\s*([^<>]+?)\\s*>', s)\n",
        "        if match:\n",
        "            return match.group(1).strip()\n",
        "        return s  # Return original if no <...> found\n",
        "\n",
        "    @staticmethod\n",
        "    def split_method_and_return(sig: str) -> tuple[str, str]:\n",
        "        \"\"\"\n",
        "        Given a signature like \"getName():string\",\n",
        "        returns (\"getName()\", \"string\").\n",
        "        If no return type is present, returns (sig, \"\").\n",
        "        \"\"\"\n",
        "        sig = sig.strip()\n",
        "        # Regex explanation:\n",
        "        # ^(.+\\(\\))   → match name() part (group 1)\n",
        "        # (?:\\s*:\\s*(.+))? → optional :returnType (group 2)\n",
        "        pattern = r'^(.+\\(\\))(?:\\s*:\\s*(.+))?$'\n",
        "        match = re.match(pattern, sig)\n",
        "        if match:\n",
        "            method = match.group(1)\n",
        "            ret_type = match.group(2) or \"\"\n",
        "            return method, ret_type\n",
        "        return sig, \"\"\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def manipulate_attr_name(attr_name):\n",
        "        if attr_name is None:\n",
        "            return \"\"\n",
        "        attr_name=attr_name.strip()\n",
        "        attr_name = XMI2AST.extract_generic_type(attr_name)\n",
        "        attr_name = XMI2AST.replace_and_or(attr_name)\n",
        "        attr_name= XMI2AST.remove_after_brackets_and_parentheses(attr_name)\n",
        "        attr_name= XMI2AST.remove_after_char(attr_name,'.')\n",
        "        attr_name= XMI2AST.remove_after_char(attr_name,'=')\n",
        "        attr_name = XMI2AST.lower_first_letter(attr_name)\n",
        "        attr_name = XMI2AST.remove_accents(attr_name)\n",
        "        attr_name = XMI2AST.remove_after_char(attr_name,\"*\")\n",
        "\n",
        "        attr_name = XMI2AST.replace_part(attr_name,\"+\")\n",
        "        attr_name = XMI2AST.replace_part(attr_name,\"#\")\n",
        "        attr_name = XMI2AST.replace_part(attr_name,\":\")\n",
        "        attr_name = XMI2AST.replace_part(attr_name,\"$\")\n",
        "        attr_name = XMI2AST.replace_part(attr_name,\"@\")\n",
        "        attr_name = XMI2AST.replace_part(attr_name,'\\\\')\n",
        "        attr_name = XMI2AST.replace_part(attr_name,\"'s\")\n",
        "        attr_name = XMI2AST.replace_part(attr_name,\">\")\n",
        "        attr_name = XMI2AST.replace_part(attr_name,\"<>\")\n",
        "        attr_name = XMI2AST.replace_part(attr_name,\"'\")\n",
        "        attr_name = XMI2AST.replace_part(attr_name,\"-\")\n",
        "        attr_name = XMI2AST.replace_part(attr_name,\"l'\")\n",
        "        attr_name = XMI2AST.replace_part(attr_name,\"_\")\n",
        "        attr_name = XMI2AST.to_camel_case(attr_name.lower())\n",
        "        return attr_name\n",
        "\n",
        "    @staticmethod\n",
        "    def manipulate_method_name(op_name):\n",
        "        if op_name is None:\n",
        "            return \"\"\n",
        "        op_name=op_name.strip()\n",
        "        op_name = XMI2AST.remove_accents(op_name)\n",
        "        op_name = XMI2AST.replace_and_or(op_name.strip())\n",
        "        op_name= XMI2AST.remove_after_char(op_name,'.')\n",
        "        op_name= XMI2AST.remove_after_char(op_name,'(')\n",
        "        op_name = XMI2AST.replace_part(op_name,\"void:\")\n",
        "        op_name = XMI2AST.replace_part(op_name,\"+void\")\n",
        "        op_name = XMI2AST.replace_part(op_name,\"+card\")\n",
        "        op_name = XMI2AST.replace_part(op_name,\"+bool\")\n",
        "        op_name = XMI2AST.replace_part(op_name,\"~\")\n",
        "        op_name = XMI2AST.replace_part(op_name,\"+\")\n",
        "        op_name = XMI2AST.replace_part(op_name,\"s'\")\n",
        "        op_name = XMI2AST.replace_part(op_name,\"_\")\n",
        "        op_name = XMI2AST.replace_part(op_name,\":\")\n",
        "        op_name = XMI2AST.replace_part(op_name,\"'s\")\n",
        "        op_name = XMI2AST.replace_part(op_name,\"*\")\n",
        "        op_name = XMI2AST.replace_part(op_name,\"<<property>>\")\n",
        "        op_name = XMI2AST.replace_part(op_name,\"-\")\n",
        "        op_name = XMI2AST.to_camel_case(op_name.lower())\n",
        "        return  op_name\n",
        "\n",
        "    @staticmethod\n",
        "    def manipulate_class_name(class_name):\n",
        "        if class_name is None:\n",
        "            return \"\"\n",
        "        class_name=class_name.strip()\n",
        "        class_name = XMI2AST.remove_accents(class_name)\n",
        "        class_name = XMI2AST.extract_after_last_dot_if_java(class_name)\n",
        "        class_name = XMI2AST.replace_part(class_name,\"+\")\n",
        "        class_name = XMI2AST.replace_part(class_name,\".\")\n",
        "        class_name = XMI2AST.replace_part(class_name,\"&\")\n",
        "        class_name = XMI2AST.replace_part(class_name,\"*\")\n",
        "        class_name = XMI2AST.extract_inner_generic(class_name)\n",
        "        class_name= XMI2AST.remove_after_brackets_and_parentheses(class_name)\n",
        "\n",
        "        class_name = XMI2AST.replace_part(class_name,\"'s\")\n",
        "        class_name = XMI2AST.remove_after_char(class_name,\"/\")\n",
        "        class_name = XMI2AST.remove_after_char(class_name,\":\")\n",
        "        class_name = XMI2AST.remove_after_char(class_name,\"`\")\n",
        "        class_name = XMI2AST.replace_part(class_name,\",\")\n",
        "        class_name = XMI2AST.remove_after_char(class_name,\"^\")\n",
        "        class_name = XMI2AST.remove_after_char(class_name,\"=\")\n",
        "        class_name = XMI2AST.to_pascal_case(class_name.lower())\n",
        "        return  class_name\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def split_method_signature(sig: str) -> tuple[str, str]:\n",
        "        \"\"\"\n",
        "        Splits a method signature \"name(params)\" into (\"name\", \"(params)\").\n",
        "        Returns (name, params_with_parentheses) or (sig, \"\") if no parentheses found.\n",
        "        \"\"\"\n",
        "        sig = sig.strip()\n",
        "        match = re.match(r'^([^(]+)(\\(.+\\))$', sig)\n",
        "        if match:\n",
        "            method_name = match.group(1).strip()\n",
        "            params = match.group(2).strip()\n",
        "            return method_name, params\n",
        "        return sig, \"\"\n",
        "\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_classes(xmi_file, file_index):\n",
        "        tree = ET.parse(xmi_file)\n",
        "        root = tree.getroot()\n",
        "\n",
        "        ns = {\n",
        "            \"xmi\": \"http://schema.omg.org/spec/XMI/2.1\",\n",
        "            \"uml\": \"http://www.eclipse.org/uml2/5.0.0/UML\",\n",
        "            \"xsi\": \"http://www.w3.org/2001/XMLSchema-instance\"\n",
        "        }\n",
        "\n",
        "        classes = []\n",
        "\n",
        "        for class_elem in root.findall(\".//packagedElement[@xsi:type='uml:Class']\", ns):\n",
        "            raw_class_name = class_elem.attrib.get(\"name\", \"\")\n",
        "            class_name = XMI2AST.manipulate_class_name(raw_class_name.strip())\n",
        "\n",
        "            if not XMI2AST.is_pascal_case(class_name) and len(class_name.strip()) > 0:\n",
        "                print(\"Error here class: \" + class_name +\" \"+ repr(class_name)+ \" file index: \" + str(file_index))\n",
        "            class_node = {\n",
        "                \"type\": \"class\",\n",
        "                \"value\": class_name,\n",
        "                \"children\": []\n",
        "            }\n",
        "\n",
        "            # Attributes\n",
        "            for attr in class_elem.findall(\"ownedAttribute\", ns):\n",
        "                raw_attr_name = attr.attrib.get(\"name\", \"\")\n",
        "                attr_name = XMI2AST.manipulate_attr_name(raw_attr_name)\n",
        "                attr_visibility_raw = attr.attrib.get(\"visibility\")\n",
        "                attr_visibility = XMI2AST.extract_visibility(attr_visibility_raw)\n",
        "\n",
        "                attr_type = \"\"\n",
        "                type_elem = attr.find(\"type\", ns)\n",
        "                if type_elem is not None:\n",
        "                    raw_type = type_elem.attrib.get('href', \"\") or type_elem.attrib.get('name', \"\")\n",
        "                    attr_type = XMI2AST.normalize_type(raw_type)\n",
        "                if not attr_type and \"type\" in attr.attrib:\n",
        "                    attr_type = XMI2AST.normalize_type(attr.attrib[\"type\"])\n",
        "\n",
        "                if not XMI2AST.is_camel_case(attr_name) and len(attr_name.strip()) > 0:\n",
        "                    print(\"Error here attribute: \" + attr_name +\" \"+ repr(attr_name)+ \" file index: \" + str(file_index))\n",
        "\n",
        "\n",
        "\n",
        "                attribute_node = {\n",
        "                    \"type\": \"attribute\",\n",
        "                    \"value\": attr_name,\n",
        "                    \"visibility\": attr_visibility,\n",
        "                    \"data_type\": attr_type\n",
        "                }\n",
        "                if len(attr_name.strip()) > 0:\n",
        "                  class_node[\"children\"].append(attribute_node)\n",
        "\n",
        "            # Methods\n",
        "            for op in class_elem.findall(\"ownedOperation\", ns):\n",
        "                raw_op_name = op.attrib.get(\"name\", \"\")\n",
        "                op_name, detected_return_type = XMI2AST.split_method_and_return(raw_op_name.strip())\n",
        "                op_name, params = XMI2AST.split_method_signature(op_name.strip())\n",
        "                op_name = XMI2AST.manipulate_method_name(op_name)\n",
        "                op_visibility_raw = op.attrib.get(\"visibility\")\n",
        "                op_visibility = XMI2AST.extract_visibility(op_visibility_raw)\n",
        "\n",
        "                return_type = \"void\"\n",
        "                for param in op.findall(\"ownedParameter\", ns):\n",
        "                    if param.attrib.get(\"direction\") == \"return\":\n",
        "                        type_elem = param.find(\"type\", ns)\n",
        "                        raw_type = \"\"\n",
        "                        if type_elem is not None:\n",
        "                            raw_type = type_elem.attrib.get('href', \"\") or type_elem.attrib.get('name', \"\")\n",
        "                        else:\n",
        "                            raw_type = param.attrib.get(\"type\", \"\")\n",
        "                        return_type = XMI2AST.normalize_type(raw_type)\n",
        "                        if not return_type or len(return_type.strip())==0:\n",
        "                            return_type = detected_return_type\n",
        "                        break\n",
        "                if not XMI2AST.is_camel_case(op_name) and len(op_name.strip()) > 0:\n",
        "                    print(\"Error here method: \" + op_name +\" \"+ repr(op_name)+ \" file index: \" + str(file_index))\n",
        "\n",
        "                if len(params.strip())==0:\n",
        "                    params=\"()\"\n",
        "\n",
        "                method_node = {\n",
        "                    \"type\": \"method\",\n",
        "                    \"value\": op_name + params,\n",
        "                    \"visibility\": op_visibility,\n",
        "                    \"data_type\": return_type\n",
        "                }\n",
        "                class_node[\"children\"].append(method_node)\n",
        "\n",
        "            classes.append(class_node)\n",
        "\n",
        "        return classes\n",
        "\n",
        "    @staticmethod\n",
        "    def convertXMI(input_path: str, output_path: str, file_index):\n",
        "        classes = XMI2AST.extract_classes(input_path, file_index)\n",
        "\n",
        "        if not classes :\n",
        "            return None, 0\n",
        "        else:\n",
        "            ast = {\n",
        "                \"type\": \"root\",\n",
        "                \"children\": classes\n",
        "            }\n",
        "            return ast, len(classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLLcdyDepPGP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def convert_all_xmi_in_dir(input_dir: str, output_dir: str):\n",
        "    count_of_classes = 0\n",
        "    count_of_files = 0\n",
        "    # Make sure output directory exists\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    file_index=-1\n",
        "    # Loop through files in input_dir\n",
        "    excluded=[1520]\n",
        "    output_data = []\n",
        "    for filename in os.listdir(input_dir):\n",
        "        file_index=file_index+1\n",
        "        if file_index < 0:\n",
        "            continue\n",
        "\n",
        "        if file_index in excluded:\n",
        "            continue\n",
        "\n",
        "        if filename.lower().endswith(\".xmi\"):\n",
        "            input_path = os.path.join(input_dir, filename)\n",
        "            # Replace .xmi extension with .json for output filename\n",
        "            output_filename = os.path.splitext(filename)[0] + \".json\"\n",
        "            output_path = os.path.join(output_dir, output_filename)\n",
        "\n",
        "\n",
        "            ast, len_classes = XMI2AST.convertXMI(input_path, output_path,file_index)\n",
        "\n",
        "            if ast is None:\n",
        "                continue\n",
        "            count_of_classes=len_classes+count_of_classes\n",
        "            count_of_files=count_of_files + 1\n",
        "            output_data.append({\"Output_AST\": ast, \"Model\": output_filename})\n",
        "            #print(f\"Converting {input_path} -> {output_path}\")\n",
        "            #with open(output_path, 'w', encoding='utf-8') as out_file:\n",
        "                #json.dump(ast, out_file, indent=2)\n",
        "            print(f\"Output saved to {output_path}\")\n",
        "\n",
        "    print(f\"extracted classes count {count_of_classes}\")\n",
        "    print(f\"files count {count_of_files}\")\n",
        "    with open(\"/content/drive/MyDrive/GenClass/data/raw/genmymodel_asts.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(output_data, f, indent=2)\n",
        "\n",
        "    with open(\"/content/drive/MyDrive/GenClass/data/raw/genmymodel_asts.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
        "        for item in output_data:\n",
        "            json.dump(item, f)\n",
        "            f.write(\"\\n\")\n",
        "\n",
        "# Example usage:\n",
        "convert_all_xmi_in_dir(\"/content/drive/MyDrive/GenClass/temp/modelset/raw-data/repo-genmymodel-uml/data\",\n",
        "                       \"/content/drive/MyDrive/GenClass/temp/modelset_AST_genmymodel\")\n",
        "\n",
        "\n",
        "# extracted classes count 32063\n",
        "# files count 3085"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4jVWosD5lEd"
      },
      "outputs": [],
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import json\n",
        "import re\n",
        "import urllib.parse\n",
        "import unicodedata\n",
        "import wordninja\n",
        "\n",
        "class Ecore2AST:\n",
        "    primitive_types = {\"string\", \"boolean\", \"int\", \"float\", \"double\", \"long\", \"short\", \"byte\", \"char\", \"eint\", \"estring\", \"eboolean\"}\n",
        "\n",
        "    relation_symbols = {\n",
        "        \"generalization\": \"<|--\",\n",
        "        \"implementation\": \"<|..\",\n",
        "        \"composition\": \"*--\",\n",
        "        \"aggregation\": \"o--\",\n",
        "        \"dependency\": \"-->\",\n",
        "        \"relation\": \"--\"\n",
        "    }\n",
        "\n",
        "    @staticmethod\n",
        "    def normalize_type(raw_type: str) -> str:\n",
        "          if not raw_type:\n",
        "                return \"\"\n",
        "\n",
        "          raw_type = urllib.parse.unquote(raw_type).strip()\n",
        "\n",
        "          if raw_type.startswith(\"_\"):\n",
        "                return \"\"\n",
        "\n",
        "          if '#' in raw_type:\n",
        "                raw_type = raw_type.split('#')[-1].lstrip('/')\n",
        "\n",
        "          raw_type = Ecore2AST.strip_path_prefix(raw_type)\n",
        "          lower_type = raw_type.lower()\n",
        "\n",
        "          # Handle common synonyms and variations\n",
        "          synonym_map = {\n",
        "            \"integer\": \"int\",\n",
        "            \"int\": \"int\",\n",
        "            \"eint\": \"int\",\n",
        "            \"bool\": \"boolean\",\n",
        "            \"boolean\": \"boolean\",\n",
        "            \"eboolean\": \"boolean\",\n",
        "            \"string\": \"string\",\n",
        "            \"estring\": \"string\",\n",
        "            \"float\": \"float\",\n",
        "            \"double\": \"double\",\n",
        "            \"long\": \"long\",\n",
        "            \"short\": \"short\",\n",
        "            \"byte\": \"byte\",\n",
        "            \"char\": \"char\"\n",
        "          }\n",
        "\n",
        "          if lower_type in synonym_map:\n",
        "                return synonym_map[lower_type]\n",
        "\n",
        "          return raw_type[0].upper() + raw_type[1:]\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def strip_path_prefix(s: str) -> str:\n",
        "        return s.split(\"/\")[-1] if \"/\" in s else s\n",
        "\n",
        "    @staticmethod\n",
        "    def to_pascal_case(name: str) -> str:\n",
        "        if not name: return \"\"\n",
        "        parts = re.split(r'[\\s_-]+', name.strip())\n",
        "        if len(parts) == 1:\n",
        "            parts = wordninja.split(name)\n",
        "        return ''.join(word.capitalize() for word in parts if word)\n",
        "\n",
        "    @staticmethod\n",
        "    def to_camel_case(name: str) -> str:\n",
        "        if not name: return \"\"\n",
        "        parts = re.split(r'[\\s_-]+', name.strip())\n",
        "        if len(parts) == 1 and parts[0].islower():\n",
        "            parts = wordninja.split(name.strip())\n",
        "        if not parts: return \"\"\n",
        "        return parts[0].lower() + ''.join(word.capitalize() for word in parts[1:])\n",
        "\n",
        "    @staticmethod\n",
        "    def remove_after_char(s: str, specific_char) -> str:\n",
        "        return s.split(specific_char, 1)[0]\n",
        "\n",
        "    @staticmethod\n",
        "    def remove_accents(text: str) -> str:\n",
        "        return ''.join(c for c in unicodedata.normalize('NFKD', text) if not unicodedata.combining(c))\n",
        "\n",
        "    @staticmethod\n",
        "    def remove_after_brackets_and_parentheses(s: str) -> str:\n",
        "        s = s.split('[')[0]\n",
        "        s = s.split('(')[0]\n",
        "        return s\n",
        "\n",
        "    @staticmethod\n",
        "    def replace_part(s: str, replaced: str, replacement: str = \"\") -> str:\n",
        "        return s.replace(replaced, replacement)\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_generic_type(s: str) -> str:\n",
        "        match = re.search(r'<\\s*([a-zA-Z0-9_]+)\\s*>', s)\n",
        "        return match.group(1) if match else s\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_visibility(_) -> str:\n",
        "        return \"+\"  # Ecore typically doesn't have visibility in XMI, default to public\n",
        "\n",
        "    @staticmethod\n",
        "    def split_method_and_return(sig: str) -> tuple[str, str]:\n",
        "        \"\"\"\n",
        "        Given a signature like \"getName():string\",\n",
        "        returns (\"getName()\", \"string\").\n",
        "        If no return type is present, returns (sig, \"\").\n",
        "        \"\"\"\n",
        "        sig = sig.strip()\n",
        "        pattern = r'^(.+\\(\\))(?:\\s*:\\s*(.+))?$'\n",
        "        match = re.match(pattern, sig)\n",
        "        if match:\n",
        "            method = match.group(1)\n",
        "            ret_type = match.group(2) or \"\"\n",
        "            return method, ret_type\n",
        "        return sig, \"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def split_method_signature(sig: str) -> tuple[str, str]:\n",
        "        \"\"\"\n",
        "        Splits a method signature \"name(params)\" into (\"name\", \"(params)\").\n",
        "        Returns (name, params_with_parentheses) or (sig, \"\") if no parentheses found.\n",
        "        \"\"\"\n",
        "        sig = sig.strip()\n",
        "        match = re.match(r'^([^(]+)(\\(.+\\))$', sig)\n",
        "        if match:\n",
        "            method_name = match.group(1).strip()\n",
        "            params = match.group(2).strip()\n",
        "            return method_name, params\n",
        "        return sig, \"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def manipulate_class_name(name):\n",
        "        if not name: return \"\"\n",
        "        name = Ecore2AST.remove_accents(name)\n",
        "        name = Ecore2AST.extract_generic_type(name)\n",
        "        name = Ecore2AST.remove_after_brackets_and_parentheses(name)\n",
        "        name = Ecore2AST.remove_after_char(name, \"/\")\n",
        "        name = Ecore2AST.remove_after_char(name, \":\")\n",
        "        name = Ecore2AST.remove_after_char(name, \"=\")\n",
        "        name = Ecore2AST.replace_part(name, \".\", \"\")\n",
        "        name = Ecore2AST.replace_part(name, \"+\", \"\")\n",
        "        name = Ecore2AST.strip_path_prefix(name)\n",
        "        return Ecore2AST.to_pascal_case(name)\n",
        "\n",
        "    @staticmethod\n",
        "    def manipulate_attr_name(name):\n",
        "        if not name: return \"\"\n",
        "        name = Ecore2AST.extract_generic_type(name)\n",
        "        name = Ecore2AST.remove_after_brackets_and_parentheses(name)\n",
        "        name = Ecore2AST.remove_after_char(name, \".\")\n",
        "        name = Ecore2AST.remove_after_char(name, \"=\")\n",
        "        name = Ecore2AST.remove_after_char(name, \"*\")\n",
        "        name = Ecore2AST.replace_part(name, \"+\", \"\")\n",
        "        name = Ecore2AST.replace_part(name, \"#\", \"\")\n",
        "        name = Ecore2AST.replace_part(name, \":\", \"\")\n",
        "        name = Ecore2AST.replace_part(name, \"$\", \"\")\n",
        "        name = Ecore2AST.replace_part(name, \"'s\", \"\")\n",
        "        name = Ecore2AST.replace_part(name, \"-\", \"\")\n",
        "        name = Ecore2AST.replace_part(name, \"_\", \"\")\n",
        "        name = Ecore2AST.remove_accents(name)\n",
        "        return Ecore2AST.to_camel_case(name.lower())\n",
        "\n",
        "    @staticmethod\n",
        "    def manipulate_method_name(op_name):\n",
        "        if not op_name: return \"\"\n",
        "        op_name = op_name.strip()\n",
        "        op_name = Ecore2AST.remove_accents(op_name)\n",
        "        op_name = Ecore2AST.remove_after_char(op_name, '.')\n",
        "        op_name = Ecore2AST.remove_after_char(op_name, '(')\n",
        "        op_name = Ecore2AST.replace_part(op_name, \"void:\", \"\")\n",
        "        op_name = Ecore2AST.replace_part(op_name, \"+void\", \"\")\n",
        "        op_name = Ecore2AST.replace_part(op_name, \"+\", \"\")\n",
        "        op_name = Ecore2AST.replace_part(op_name, \"_\", \"\")\n",
        "        op_name = Ecore2AST.replace_part(op_name, \":\", \"\")\n",
        "        op_name = Ecore2AST.replace_part(op_name, \"'s\", \"\")\n",
        "        op_name = Ecore2AST.replace_part(op_name, \"*\", \"\")\n",
        "        op_name = Ecore2AST.replace_part(op_name, \"-\", \"\")\n",
        "        return Ecore2AST.to_camel_case(op_name.lower())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_classes_and_relations(ecore_file, file_index):\n",
        "        def format_multiplicity(lower: str, upper: str) -> str:\n",
        "            l = lower or \"1\"\n",
        "            u = upper or \"1\"\n",
        "            if u == \"-1\":\n",
        "                u = \"*\"\n",
        "            if l == \"-1\":\n",
        "                l = \"*\"\n",
        "            if l == u:\n",
        "                return l\n",
        "            return f\"{l}..{u}\"\n",
        "\n",
        "\n",
        "        tree = ET.parse(ecore_file)\n",
        "        root = tree.getroot()\n",
        "        ns = {\n",
        "            \"xmi\": \"http://www.omg.org/XMI\",\n",
        "            \"ecore\": \"http://www.eclipse.org/emf/2002/Ecore\",\n",
        "            \"xsi\": \"http://www.w3.org/2001/XMLSchema-instance\"\n",
        "        }\n",
        "\n",
        "        class_map = {}\n",
        "        id_to_type = {}\n",
        "\n",
        "        for classifier in root.findall(\".//eClassifiers[@xsi:type='ecore:EClass']\", ns):\n",
        "            class_id = classifier.attrib.get(\"{http://www.omg.org/XMI}id\")\n",
        "            raw_name = classifier.attrib.get(\"name\", \"\")\n",
        "            class_name = Ecore2AST.manipulate_class_name(raw_name)\n",
        "            class_name = Ecore2AST.strip_path_prefix(class_name)\n",
        "            if class_id:\n",
        "                class_map[class_id] = class_name\n",
        "                id_to_type[class_id] = class_name\n",
        "\n",
        "        ast_classes = []\n",
        "        for class_elem in root.findall(\".//eClassifiers[@xsi:type='ecore:EClass']\", ns):\n",
        "            raw_class_name = class_elem.attrib.get(\"name\", \"\")\n",
        "            class_name = Ecore2AST.manipulate_class_name(raw_class_name)\n",
        "            class_name = Ecore2AST.strip_path_prefix(class_name)\n",
        "            class_node = {\n",
        "                \"type\": \"class\",\n",
        "                \"value\": class_name,\n",
        "                \"children\": []\n",
        "            }\n",
        "\n",
        "            # Attributes\n",
        "            for attr in class_elem.findall(\"eStructuralFeatures[@xsi:type='ecore:EAttribute']\", ns):\n",
        "                  attr_name = Ecore2AST.manipulate_attr_name(attr.attrib.get(\"name\", \"\"))\n",
        "                  attr_type = Ecore2AST.normalize_type(attr.attrib.get(\"eType\", \"\"))\n",
        "                  attr_type = Ecore2AST.strip_path_prefix(attr_type)\n",
        "\n",
        "                  # Extract visibility from annotations if available\n",
        "                  visibility = \"+\"\n",
        "                  for annotation in attr.findall(\"eAnnotations\", ns):\n",
        "                        if annotation.attrib.get(\"source\", \"\").lower() == \"visibility\":\n",
        "                              for detail in annotation.findall(\"details\", ns):\n",
        "                                    if detail.attrib.get(\"key\") == \"value\":\n",
        "                                          raw_visibility = detail.attrib.get(\"value\", \"+\").lower()\n",
        "                                          if raw_visibility in [\"public\", \"+\"]:\n",
        "                                                visibility = \"+\"\n",
        "                                          elif raw_visibility in [\"private\", \"-\"]:\n",
        "                                                visibility = \"-\"\n",
        "                                          elif raw_visibility in [\"protected\", \"#\"]:\n",
        "                                                visibility = \"#\"\n",
        "                                          elif raw_visibility in [\"package\", \"~\"]:\n",
        "                                                visibility = \"~\"\n",
        "                                          break\n",
        "\n",
        "                  if attr_name:\n",
        "                        class_node[\"children\"].append({\n",
        "                              \"type\": \"attribute\",\n",
        "                              \"value\": attr_name,\n",
        "                              \"visibility\": visibility,\n",
        "                              \"data_type\": attr_type\n",
        "                        })\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            # Methods (Operations)\n",
        "            for op in class_elem.findall(\"eOperations\", ns):\n",
        "                  raw_op_name = op.attrib.get(\"name\", \"\")\n",
        "                  op_name, detected_return_type = Ecore2AST.split_method_and_return(raw_op_name.strip())\n",
        "                  op_name, params = Ecore2AST.split_method_signature(op_name.strip())\n",
        "                  op_name = Ecore2AST.manipulate_method_name(op_name)\n",
        "\n",
        "                  # Extract visibility from annotations if available\n",
        "                  visibility = \"+\"\n",
        "                  for annotation in op.findall(\"eAnnotations\", ns):\n",
        "                        if annotation.attrib.get(\"source\", \"\").lower() == \"visibility\":\n",
        "                              for detail in annotation.findall(\"details\", ns):\n",
        "                                    if detail.attrib.get(\"key\") == \"value\":\n",
        "                                          raw_visibility = detail.attrib.get(\"value\", \"+\").lower()\n",
        "                                          if raw_visibility in [\"public\", \"+\"]:\n",
        "                                                visibility = \"+\"\n",
        "                                          elif raw_visibility in [\"private\", \"-\"]:\n",
        "                                                visibility = \"-\"\n",
        "                                          elif raw_visibility in [\"protected\", \"#\"]:\n",
        "                                                visibility = \"#\"\n",
        "                                          elif raw_visibility in [\"package\", \"~\"]:\n",
        "                                                visibility = \"~\"\n",
        "                                          break\n",
        "\n",
        "                  # Get return type from operation\n",
        "                  return_type = \"void\"\n",
        "                  for param in op.findall(\"eParameters\", ns):\n",
        "                        if param.attrib.get(\"direction\", \"\").lower() == \"return\":\n",
        "                              raw_type = param.attrib.get(\"eType\", \"\")\n",
        "                              if raw_type.startswith(\"#//\"):\n",
        "                                    type_id = raw_type[3:]\n",
        "                                    return_type = class_map.get(type_id, Ecore2AST.normalize_type(raw_type))\n",
        "                              else:\n",
        "                                    return_type = Ecore2AST.normalize_type(raw_type)\n",
        "                              break\n",
        "\n",
        "                  if not return_type:\n",
        "                        return_type = detected_return_type\n",
        "\n",
        "                  method_node = {\n",
        "                        \"type\": \"method\",\n",
        "                        \"value\": op_name + \"()\",\n",
        "                        \"visibility\": visibility,\n",
        "                        \"data_type\": return_type\n",
        "                  }\n",
        "                  class_node[\"children\"].append(method_node)\n",
        "\n",
        "            # References\n",
        "            for ref in class_elem.findall(\"eStructuralFeatures[@xsi:type='ecore:EReference']\", ns):\n",
        "                ref_name = Ecore2AST.manipulate_attr_name(ref.attrib.get(\"name\", \"\"))\n",
        "                ref_type_raw = ref.attrib.get(\"eType\", \"\")\n",
        "                ref_type_id = \"\"\n",
        "                if ref_type_raw.startswith(\"#//\"):\n",
        "                    ref_type_id = ref_type_raw[3:]\n",
        "                ref_type = class_map.get(ref_type_id, Ecore2AST.normalize_type(ref_type_raw))\n",
        "                ref_type = Ecore2AST.strip_path_prefix(ref_type)\n",
        "\n",
        "                containment = ref.attrib.get(\"containment\", \"false\").lower() == \"true\"\n",
        "                aggregation = ref.attrib.get(\"aggregation\", \"\").lower()\n",
        "                derived = ref.attrib.get(\"derived\", \"false\").lower() == \"true\"\n",
        "\n",
        "                \"\"\"\n",
        "                if ref_name:\n",
        "                    class_node[\"children\"].append({\n",
        "                        \"type\": \"attribute\",\n",
        "                        \"value\": ref_name,\n",
        "                        \"visibility\": \"+\",\n",
        "                        \"data_type\": ref_type\n",
        "                    })\n",
        "                \"\"\"\n",
        "\n",
        "                if ref_type and ref_type != class_name:\n",
        "                    rel_type = \"--\"\n",
        "                    if containment or aggregation == \"composite\":\n",
        "                        rel_type = \"*--\"\n",
        "                    elif aggregation == \"shared\":\n",
        "                        rel_type = \"o--\"\n",
        "                    else:\n",
        "                        rel_type = \"-->\"  # default: plain association\n",
        "\n",
        "                    multiplicity1 = format_multiplicity(ref.attrib.get(\"lowerBound\"), ref.attrib.get(\"upperBound\"))\n",
        "\n",
        "                    # Resolve multiplicity2 using eOpposite if available\n",
        "                    multiplicity2 = \"1\"  # default fallback\n",
        "                    e_opposite = ref.attrib.get(\"eOpposite\")\n",
        "                    if e_opposite:\n",
        "                        e_opposite_id = e_opposite.split(\"/\")[-1]\n",
        "                        for opp in root.findall(\".//eStructuralFeatures[@xsi:type='ecore:EReference']\", ns):\n",
        "                            opp_id = opp.attrib.get(\"{http://www.omg.org/XMI}id\")\n",
        "                            if opp_id and opp_id.endswith(e_opposite_id):\n",
        "                                opp_lower = opp.attrib.get(\"lowerBound\")\n",
        "                                opp_upper = opp.attrib.get(\"upperBound\")\n",
        "                                multiplicity2 = format_multiplicity(opp_lower, opp_upper)\n",
        "                                break\n",
        "\n",
        "                    relation_node = {\n",
        "                        \"type\": \"relation\",\n",
        "                        \"value\": rel_type,\n",
        "                        \"multiplicity1\": multiplicity1,\n",
        "                        \"multiplicity2\": multiplicity2,\n",
        "                        \"children\": [\n",
        "                            {\"type\": \"class\", \"value\": ref_type}\n",
        "                        ]\n",
        "                    }\n",
        "                    label = ref.attrib.get(\"name\", \"\")\n",
        "                    if label:\n",
        "                        relation_node[\"label\"] = label\n",
        "                    class_node[\"children\"].append(relation_node)\n",
        "\n",
        "\n",
        "\n",
        "            # Super types\n",
        "            super_types = class_elem.attrib.get(\"eSuperTypes\", \"\")\n",
        "            for super_ref in super_types.split():\n",
        "                if super_ref.startswith(\"#//\"):\n",
        "                    super_class_id = super_ref[3:]\n",
        "                    super_elem = class_map.get(super_class_id)\n",
        "\n",
        "                    if super_elem is not None:\n",
        "                        is_interface = super_elem.attrib.get(\"interface\", \"false\").lower() == \"true\"\n",
        "                        is_abstract = super_elem.attrib.get(\"abstract\", \"false\").lower() == \"true\"\n",
        "\n",
        "                        super_class_name = Ecore2AST.manipulate_class_name(super_class_id)\n",
        "                        super_class_name = Ecore2AST.strip_path_prefix(super_class_name)\n",
        "\n",
        "                        rel_value = \"..|>\" if is_interface else \"--|>\"\n",
        "\n",
        "                        generalization_relation = {\n",
        "                            \"type\": \"relation\",\n",
        "                            \"value\": rel_value,\n",
        "                            \"multiplicity1\": \"1\",\n",
        "                            \"multiplicity2\": \"1\",\n",
        "                            \"label\": \"\",\n",
        "                            \"children\": [\n",
        "                                {\"type\": \"class\", \"value\": super_class_name}\n",
        "                            ]\n",
        "                        }\n",
        "                        if not super_class_name==\"AbstractElement\":\n",
        "                            class_node[\"children\"].append(generalization_relation)\n",
        "\n",
        "            ast_classes.append(class_node)\n",
        "        return ast_classes\n",
        "\n",
        "    @staticmethod\n",
        "    def convertEcore(input_path: str, output_path: str, file_index):\n",
        "        elements = Ecore2AST.extract_classes_and_relations(input_path, file_index)\n",
        "\n",
        "        if not elements:\n",
        "            return None, 0\n",
        "        else:\n",
        "            ast = {\n",
        "                \"type\": \"root\",\n",
        "                \"children\": elements\n",
        "            }\n",
        "            if output_path:\n",
        "                with open(output_path, 'w') as f:\n",
        "                    json.dump(ast, f, indent=2)\n",
        "            return ast, len(elements)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Cgfe4ER5mat"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "def find_all_ecore_files(input_dir: str):\n",
        "    ecore_files = []\n",
        "    for root, _, files in os.walk(input_dir):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(\".ecore\"):\n",
        "                full_path = os.path.join(root, file)\n",
        "                ecore_files.append(full_path)\n",
        "    return ecore_files\n",
        "\n",
        "def convert_all_ecore_files(ecore_files,input_dir: str, output_dir: str):\n",
        "    count_of_classes = 0\n",
        "    count_of_files = 0\n",
        "    file_index = -1\n",
        "    excluded = [236]  # Customize this as needed\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    output_data=[]\n",
        "    for filename in ecore_files:\n",
        "        file_index += 1\n",
        "\n",
        "        if file_index < 0:\n",
        "            continue\n",
        "\n",
        "        if file_index in excluded:\n",
        "            continue\n",
        "\n",
        "        if filename.lower().endswith(\".ecore\"):\n",
        "            input_path = os.path.join(input_dir, filename)\n",
        "            output_filename = os.path.splitext(filename)[0] + \".json\"\n",
        "            output_path = os.path.join(output_dir, f\"{file_index}.json\")\n",
        "\n",
        "            ast, len_classes  = Ecore2AST.convertEcore(input_path,output_path,file_index)\n",
        "\n",
        "            if ast is None:\n",
        "                #print(f\"⚠️  Skipped (no classes): {input_path}\")\n",
        "                continue\n",
        "\n",
        "\n",
        "            count_of_classes += len_classes\n",
        "            count_of_files += 1\n",
        "            output_data.append({\"Output_AST\": ast, \"Model\": output_filename})\n",
        "            #with open(output_path, 'w', encoding='utf-8') as out_file:\n",
        "                #json.dump(ast, out_file, indent=2)\n",
        "\n",
        "            print(f\"✅ Converted [{file_index}] {input_path} → {output_path} ({len_classes} classes)\")\n",
        "\n",
        "    print(f\"📦 Total extracted classes: {count_of_classes}\")\n",
        "    print(f\"📁 Total files converted: {count_of_files}\")\n",
        "    with open(\"/content/drive/MyDrive/GenClass/data/raw/ecore_asts.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(output_data, f, indent=2)\n",
        "\n",
        "    with open(\"/content/drive/MyDrive/GenClass/data/raw/ecore_asts.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
        "        for item in output_data:\n",
        "            json.dump(item, f)\n",
        "            f.write(\"\\n\")\n",
        "\n",
        "\n",
        "# Example usage\n",
        "input_dir = \"/content/drive/MyDrive/GenClass/temp/modelset/raw-data/repo-ecore-all\"\n",
        "output_dir = \"/content/drive/MyDrive/GenClass/temp/modelset_AST_ecore_no_empty\"\n",
        "\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/GenClass/temp/ecore_files.txt\"\n",
        "\n",
        "if not os.path.exists(file_path):\n",
        "    ecore_paths = find_all_ecore_files(input_dir)\n",
        "    print(f\"🔍 Found {len(ecore_paths)} .ecore files.\")\n",
        "\n",
        "    with open(file_path, 'w', encoding='utf-8') as f:\n",
        "        for path in ecore_paths:\n",
        "            f.write(path + '\\n')\n",
        "else:\n",
        "    print(\"✅ File already exists, skipping scan.\")\n",
        "\n",
        "\n",
        "\n",
        "with open(file_path, 'r', encoding='utf-8') as f:\n",
        "    ecore_paths = [line.strip() for line in f if line.strip()]\n",
        "\n",
        "convert_all_ecore_files(ecore_paths, input_dir, output_dir)\n",
        "# Total extracted classes: 140619\n",
        "# Total files converted: 5432"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "with open(\"/content/drive/MyDrive/GenClass/temp/ecore_files.txt\", 'r', encoding='utf-8') as f:\n",
        "    ecore_paths = [line.strip() for line in f if line.strip()]\n",
        "\n",
        "#input_path =ecore_paths[108]\n",
        "input_path =random.choice(ecore_paths)\n",
        "input_path =\"/content/drive/MyDrive/GenClass/temp/modelset/raw-data/repo-ecore-all/data/abreslav/astrans/ru.ifmo.rain.astrans.interpreter.trace/model/trace.ecore\"\n",
        "ast, len_classes = Ecore2AST.convertEcore(input_path,\"fdsf\",1)\n",
        "print(json.dumps(ast, indent=2))"
      ],
      "metadata": {
        "id": "ezUKXDRzhm_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wordninja\n",
        "import re\n",
        "class NameFormatter:\n",
        "\n",
        "    @staticmethod\n",
        "    def to_camel_case_attr(name: str) -> str:\n",
        "        if not name:\n",
        "            return \"\"\n",
        "\n",
        "        # First try splitting by delimiters (_ - space)\n",
        "        parts = re.split(r'[\\s_-]+', name.strip())\n",
        "\n",
        "        # If splitting fails (i.e., only one part and all lowercase), use wordninja\n",
        "        if len(parts) == 1 and parts[0].islower():\n",
        "            parts = wordninja.split(name.strip())\n",
        "\n",
        "        if not parts:\n",
        "            return \"\"\n",
        "\n",
        "        return parts[0].lower() + ''.join(word.capitalize() for word in parts[1:])\n",
        "\n",
        "    @staticmethod\n",
        "    def to_camel_case_method(name: str) -> str:\n",
        "        if not name:\n",
        "            return \"\"\n",
        "\n",
        "        if '(' in name:\n",
        "            method_name, rest = name.split('(', 1)\n",
        "            camel_name = NameFormatter.to_camel_case_attr(method_name.strip())\n",
        "            return f\"{camel_name}({rest}\"\n",
        "        else:\n",
        "            # No parentheses, treat whole string as method name\n",
        "            return NameFormatter.to_camel_case_attr(name.strip())\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def to_pascal_case(name: str) -> str:\n",
        "        if not name:\n",
        "            return \"\"\n",
        "\n",
        "        # First split on delimiters like space, underscore, dash\n",
        "        parts = re.split(r'[\\s_-]+', name.strip())\n",
        "\n",
        "        # If splitting didn't produce multiple parts, use wordninja\n",
        "        if len(parts) == 1:\n",
        "            parts = wordninja.split(name)\n",
        "\n",
        "        return ''.join(word.capitalize() for word in parts if word)\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def lowercase_first_letter(s: str) -> str:\n",
        "        return s[:1].lower() + s[1:] if s else \"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def uppercase_first_letter(s: str) -> str:\n",
        "        return s[:1].upper() + s[1:] if s else \"\"\n",
        "\n",
        "\n",
        "a = NameFormatter.to_camel_case_method(\"publicoperation\")\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrQHyy6P0RsS",
        "outputId": "769f7889-6bae-4e2f-d98b-a0d59ab5f6dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "publicOperation\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}